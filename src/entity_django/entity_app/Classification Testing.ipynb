{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7934c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\spacy\\util.py:837: UserWarning: [W095] Model 'en_core_web_lg' (3.4.0) was trained with spaCy v3.4 and may not be 100% compatible with the current version (3.3.1). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import spacy\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg', disable=['ner'])\n",
    "nlp.remove_pipe('tagger')\n",
    "nlp.remove_pipe('parser')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8059b7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect(\"C:/Users/User/OneDrive - University of Glasgow/University Year 4/Individual Project/2464980P-L4-Project/src/entity_django/db.sqlite3\")\n",
    "\n",
    "cur = con.cursor()\n",
    "\n",
    "entities={}\n",
    "for row in cur.execute('SELECT * FROM entity_app_entity;'):\n",
    "    entities[row[0]]=row[1]\n",
    "    \n",
    "instances={}\n",
    "for row in cur.execute('SELECT * FROM entity_app_instance;'):\n",
    "    documentID=row[3]\n",
    "    entityID=row[4]\n",
    "    try:\n",
    "        instances[documentID]+=entities[entityID]\n",
    "    except KeyError:\n",
    "        instances[documentID]=entities[entityID]\n",
    "\n",
    "documents={}\n",
    "for row in cur.execute('SELECT * FROM entity_app_document;'):\n",
    "    documents[row[0]]=row[2].replace(\".html.gz\",\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1a35047",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRUTHS=\"C:/Users/User/Desktop/project_data/truths.txt\"\n",
    "with open (TRUTHS, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "truths={}\n",
    "for line in lines:\n",
    "    line=line.replace(\"\\n\",\"\").replace(\" \",\"/\").split(\"/\")[-2:]\n",
    "    truths[line[0]]=line[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "929c0d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['filename', 'text', 'truth'])\n",
    "\n",
    "i=0\n",
    "for docid in documents.keys():\n",
    "    try:\n",
    "        filename=documents[docid]\n",
    "        truth=int(truths[filename])\n",
    "        text=instances[docid]\n",
    "        df.loc[i] = [filename,text,truth]\n",
    "        i+=1\n",
    "    except KeyError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2252089",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_pipeline(text):\n",
    "    tokens = []\n",
    "    doc = nlp(text)\n",
    "    for t in doc:\n",
    "        if not t.is_stop and not t.is_punct and not t.is_space:\n",
    "            tokens.append(t.lemma_.lower())\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "918d3c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect(\"C:/Users/User/OneDrive - University of Glasgow/University Year 4/Individual Project/2464980P-L4-Project/src/entity_django/db.sqlite3\")\n",
    "\n",
    "cur = con.cursor()\n",
    "\n",
    "sensitivity={}\n",
    "for row in cur.execute('SELECT * FROM entity_app_instance;'):\n",
    "    documentID=row[3]\n",
    "    entityID=row[4]\n",
    "    \n",
    "    filename=documents[documentID]\n",
    "    truth=truths[filename]\n",
    "    \n",
    "    abstract=entities[entityID]\n",
    "    if abstract in list(sensitivity.keys()):\n",
    "        if truth==1 and sensitivity[abstract]==1:\n",
    "            continue\n",
    "        elif truth==1 and sensitivity[abstract]==0:\n",
    "            sensitivity[abstract]=1\n",
    "    else:\n",
    "        sensitivity[abstract]=truth\n",
    "con.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c1c0c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(columns=['abstract','truth'])\n",
    "i=0\n",
    "for abstract in sensitivity.keys():\n",
    "    try:\n",
    "        test_df.loc[i] = [abstract,int(sensitivity[abstract])]\n",
    "        i+=1\n",
    "    except KeyError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "296deb74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2400\\3052083830.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  merged=sens.append(not_sens, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()#tokenizer=text_pipeline,binary=True)\n",
    "\n",
    "sens=df[df['truth']==1]\n",
    "not_sens=df[df['truth']==0].sample(n=len(sens),replace=False)\n",
    "merged=sens.append(not_sens, ignore_index=True)\n",
    "\n",
    "train_labels = merged['truth']\n",
    "train_features = tfidf_vectorizer.fit_transform(merged['text'].tolist())\n",
    "\n",
    "test_labels = test_df['truth']\n",
    "test_features = tfidf_vectorizer.transform(test_df['abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "04e20345",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "classifier = SGDClassifier(loss='log')\n",
    "#classifier = MLPClassifier(max_iter=10)\n",
    "#classifier = MultinomialNB()\n",
    "#classifier = LinearSVC()\n",
    "classifier_fitted = classifier.fit(train_features,train_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d2b09b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>truth</th>\n",
       "      <th>predictions</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amman (English: /əˈmɑːn/; Arabic: عَمَّان, ʻam...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.358722</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hussein bin Talal (Arabic: الحسين بن طلال, Al-...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.700499</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arabic (اَلْعَرَبِيَّةُ, al-ʿarabiyyah [al ʕar...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.592673</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hashemite is a very rare barium chromate miner...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.567529</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Terrorism, in its broadest sense, is the use o...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.536845</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19646</th>\n",
       "      <td>PRISA Televisión, S.A.U (PRISA TV) is a pay TV...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.353176</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19647</th>\n",
       "      <td>Devin Garrett Townsend (born May 5, 1972) is a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.358247</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19648</th>\n",
       "      <td>Meggen is a municipality in the district of Lu...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.503776</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19649</th>\n",
       "      <td>Sarah Helen Prescott is Professor of English L...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.285943</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19650</th>\n",
       "      <td>WMDT (channel 47) is a television station in S...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.508305</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19651 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                abstract  truth  predictions  \\\n",
       "0      Amman (English: /əˈmɑːn/; Arabic: عَمَّان, ʻam...      0     0.358722   \n",
       "1      Hussein bin Talal (Arabic: الحسين بن طلال, Al-...      0     0.700499   \n",
       "2      Arabic (اَلْعَرَبِيَّةُ, al-ʿarabiyyah [al ʕar...      0     0.592673   \n",
       "3      Hashemite is a very rare barium chromate miner...      0     0.567529   \n",
       "4      Terrorism, in its broadest sense, is the use o...      0     0.536845   \n",
       "...                                                  ...    ...          ...   \n",
       "19646  PRISA Televisión, S.A.U (PRISA TV) is a pay TV...      0     0.353176   \n",
       "19647  Devin Garrett Townsend (born May 5, 1972) is a...      0     0.358247   \n",
       "19648  Meggen is a municipality in the district of Lu...      0     0.503776   \n",
       "19649  Sarah Helen Prescott is Professor of English L...      0     0.285943   \n",
       "19650  WMDT (channel 47) is a television station in S...      0     0.508305   \n",
       "\n",
       "       prediction  \n",
       "0               1  \n",
       "1               1  \n",
       "2               1  \n",
       "3               1  \n",
       "4               1  \n",
       "...           ...  \n",
       "19646           1  \n",
       "19647           1  \n",
       "19648           1  \n",
       "19649           0  \n",
       "19650           1  \n",
       "\n",
       "[19651 rows x 4 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = classifier_fitted._predict_proba_lr(test_features)[:,0]\n",
    "predicted_df = test_df\n",
    "predicted_df['predictions'] = 1-predicted\n",
    "predicted_df['prediction'] = predicted_df['predictions'].apply(lambda x : 1 if x>0.33 else 0)\n",
    "predicted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8bdcd2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Score = 0.22036685641998735\n",
      "Recall Score = 0.9065833983866771\n",
      "F1 Score = 0.3545514679692668\n",
      "F2 Score = 0.5586556346610224\n",
      "Balanced Accuracy Score = 0.5634258085050794\n"
     ]
    }
   ],
   "source": [
    "y_true=predicted_df['truth']\n",
    "y_pred=predicted_df['prediction']\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "print(\"Precision Score =\",precision_score(y_true, y_pred, pos_label=1))\n",
    "print(\"Recall Score =\",recall_score(y_true, y_pred, pos_label=1))\n",
    "print(\"F1 Score =\",f1_score(y_true, y_pred, pos_label=1))\n",
    "print(\"F2 Score =\",fbeta_score(y_true, y_pred, pos_label=1, beta=2))\n",
    "print(\"Balanced Accuracy Score =\",balanced_accuracy_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e0a96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(predicted_df['truth'], predicted_df['prediction'], target_names=['unsensitive','sensitive']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e544ff55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pickle\n",
    "#pickle.dump(SVC_fitted, open('classifier.pkl', \"wb\"))\n",
    "#pickle.dump(tfidf_vectorizer, open('vectorizer.pkl', \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cacc867",
   "metadata": {},
   "outputs": [],
   "source": [
    "sens=test_df[test_df['truth']==1]\n",
    "not_sens=test_df[test_df['truth']==0]\n",
    "print(len(sens))\n",
    "print(len(not_sens))\n",
    "train_df_=pd.concat([sens.iloc[:],not_sens.iloc[:]])\n",
    "test_df_=pd.concat([sens.iloc[:],not_sens.iloc[:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ceec07",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "train_labels = train_df_['truth']\n",
    "train_features = tfidf_vectorizer.fit_transform(train_df_['abstract'].tolist())\n",
    "\n",
    "test_labels = test_df_['truth']\n",
    "test_features = tfidf_vectorizer.transform(test_df_['abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac6a831",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SGDClassifier(loss='log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14496cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "predicted = cross_val_predict(clf, train_features, train_labels, cv=6, method='predict_proba')\n",
    "predicted_df = test_df_\n",
    "predicted_df['predictions'] = 1-predicted\n",
    "#predicted_df.sort_values(by='predictions', ascending=False).head(30)\n",
    "predicted_df['prediction'] = predicted_df['predictions'].apply(lambda x : 1 if x>0.33 else 0)\n",
    "predicted_df.sort_values(['predictions'], ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2e9030",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true=predicted_df['truth']\n",
    "y_pred=predicted_df['prediction']\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "print(\"Precision Score =\",precision_score(y_true, y_pred, pos_label=1))\n",
    "print(\"Recall Score =\",recall_score(y_true, y_pred, pos_label=1))\n",
    "print(\"F1 Score =\",f1_score(y_true, y_pred, pos_label=1))\n",
    "print(\"F2 Score =\",fbeta_score(y_true, y_pred, pos_label=1, beta=2))\n",
    "print(\"Balanced Accuracy Score =\",balanced_accuracy_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbd3520",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
